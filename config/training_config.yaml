# Training Configuration for Workflow Optimization
# Combines MCTS-based search with GRPO policy optimization

# Dataset configuration
dataset:
  name: AIME24
  data_path: ./data/aime24/data.json
  train_ratio: 0.8
  sample_size: null  # Use all if null

# MCTS (Monte Carlo Tree Search) parameters
mcts:
  num_iterations: 10          # Iterations per MCTS round
  num_samples_per_iteration: 3 # Samples per iteration
  num_search_rounds: 5        # Number of search rounds

# GRPO (Group Refined Policy Optimization) parameters
grpo:
  learning_rate: 1.0e-5       # Base learning rate
  lora_learning_rate: 5.0e-4  # LoRA learning rate
  num_epochs: 3               # Epochs per GRPO training
  batch_size: 4               # Batch size
  gradient_accumulation_steps: 2
  gamma: 0.99                 # Discount factor
  lam: 0.95                   # GAE lambda
  entropy_coeff: 0.01         # Entropy coefficient
  value_coeff: 0.5            # Value coefficient
  max_grad_norm: 1.0          # Gradient clipping

# Model configuration
model:
  name: /root/models/Qwen2.5-7B-Instruct  # 本地模型路径 (也可以用 Qwen/Qwen2.5-7B-Instruct 从 HuggingFace 下载)
  use_lora: true              # Use LoRA fine-tuning
  lora_rank: 8                # LoRA rank
  lora_alpha: 16              # LoRA alpha

# Training parameters
training:
  num_epochs: 3               # Total training epochs
  num_episodes: 3             # Episodes per epoch
  problems_per_episode: 10    # Problems per episode (increased from 5 to 10 for better coverage)
  device: cuda                # Device (cuda or cpu)

# Paths configuration
paths:
  aflow_path: ./AFlow                             # Local AFlow directory (will be auto-detected)
  workspace_path: ./outputs                       # Local output directory
  checkpoint_path: ./checkpoints                  # Checkpoint directory
  log_path: ./logs                                # Log directory
  drive_path: /content/drive/MyDrive/agentworkflow # Google Drive backup path

# Checkpoint and logging
checkpoint:
  save_every_n_steps: 100    # Save every N steps
  save_every_n_epochs: 1     # Save every N epochs

logging:
  level: INFO                # Logging level (DEBUG, INFO, WARNING, ERROR)
  save_to_file: true         # Save logs to file
  log_file: ./logs/training.log
