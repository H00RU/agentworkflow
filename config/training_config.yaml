# Training Configuration for Workflow Optimization
# Combines MCTS-based search with GRPO policy optimization

# Dataset configuration
# Supported datasets: AIME24, MATH, GSM8K, HumanEval, MBPP
# If data_path is not specified, uses default from dataset configuration
dataset:
  name: MATH                    # Change to any supported dataset
  # data_path: ./data/math/math_validate.jsonl  # Optional, uses default if not specified
  train_ratio: 0.8
  sample_size: null            # Use all if null

# MCTS (Monte Carlo Tree Search) parameters
mcts:
  num_iterations: 10          # Iterations per MCTS round
  num_samples_per_iteration: 3 # Samples per iteration
  num_search_rounds: 5        # Number of search rounds

# GRPO (Group Refined Policy Optimization) parameters
grpo:
  learning_rate: 1.0e-5       # Base learning rate
  lora_learning_rate: 5.0e-4  # LoRA learning rate
  num_epochs: 2               # Epochs per GRPO training (reduced for speed)
  batch_size: 4               # Batch size
  gradient_accumulation_steps: 2
  gamma: 0.99                 # Discount factor
  lam: 0.95                   # GAE lambda
  entropy_coeff: 0.01         # Entropy coefficient
  value_coeff: 0.5            # Value coefficient
  max_grad_norm: 1.0          # Gradient clipping

# Model configuration
model:
  name: /root/models/Qwen2.5-7B-Instruct  # 本地模型路径 (也可以用 Qwen/Qwen2.5-7B-Instruct 从 HuggingFace 下载)
  use_lora: true              # Use LoRA fine-tuning
  lora_rank: 8                # LoRA rank
  lora_alpha: 16              # LoRA alpha

# Training parameters - OPTIMIZED FOR 5 HOURS
training:
  num_epochs: 5               # Total training epochs (increased for better learning)
  num_episodes: 3             # Episodes per epoch
  problems_per_episode: 15    # Problems per episode (maximized for 5h window)
  device: cuda                # Device (cuda or cpu)
  # Total: 5 × 3 × 15 = 225 instances, ~9.4× coverage per problem, ~4.5-5h

# Paths configuration
paths:
  aflow_path: ./AFlow                             # Local AFlow directory (will be auto-detected)
  workspace_path: ./outputs                       # Local output directory
  checkpoint_path: ./checkpoints                  # Checkpoint directory
  log_path: ./logs                                # Log directory
  drive_path: /content/drive/MyDrive/agentworkflow # Google Drive backup path

# Checkpoint and logging
checkpoint:
  save_every_n_steps: 100    # Save every N steps
  save_every_n_epochs: 1     # Save every N epochs

logging:
  level: INFO                # Logging level (DEBUG, INFO, WARNING, ERROR)
  save_to_file: true         # Save logs to file
  log_file: ./logs/training.log
